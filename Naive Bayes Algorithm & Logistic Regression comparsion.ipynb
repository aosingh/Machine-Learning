{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from itertools import chain, groupby\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "import numpy as np\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "    \n",
    "    def __init__(self, df, output_col_name, features):\n",
    "        self.df = df\n",
    "        self.conditional_probabilites = {}\n",
    "        self.prior_probabilites = {}\n",
    "        self.output = output_col_name\n",
    "        self.features = features\n",
    "        \n",
    "    def calculate_prior_probabilites(self):\n",
    "        groups = self.df.groupby(self.output).groups\n",
    "        for x in groups:\n",
    "            self.prior_probabilites[x] = len(groups[x])/len(df)\n",
    "    \n",
    "    def calculate_conditional_probabilites(self):\n",
    "        for x in self.features:\n",
    "            if x != self.output:\n",
    "                self.conditional_probabilites[x] = self.df.groupby(self.output)[x].value_counts()/self.df.groupby(self.output)[x].count()\n",
    "                \n",
    "    def train(self):\n",
    "        self.calculate_prior_probabilites()\n",
    "        self.calculate_conditional_probabilites()\n",
    "    \n",
    "    def predict(self, row):\n",
    "        posterior_prob = {}\n",
    "        \n",
    "        # Initialize the posterior probability as same as the priors\n",
    "        for x in self.prior_probabilites:\n",
    "            posterior_prob[x] = self.prior_probabilites[x]\n",
    "        \n",
    "        for label in posterior_prob:\n",
    "            for x in self.features:\n",
    "                if x != self.output:\n",
    "                    if label in self.conditional_probabilites[x] and row[x] in self.conditional_probabilites[x].get(label):\n",
    "                        posterior_prob[label] *= self.conditional_probabilites[x].get(label).get(row[x])\n",
    "                    else:\n",
    "                        posterior_prob[label] = 0\n",
    "                        break\n",
    "        return max(posterior_prob, key=posterior_prob.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    \n",
    "    def __init__(self, X, output, w, alpha):\n",
    "        self.X = X\n",
    "        self.output = output\n",
    "        self.alpha = alpha\n",
    "        self.w = w\n",
    "    \n",
    "    @staticmethod\n",
    "    def sigmoid_function(x):\n",
    "        val = 1/(1 + np.exp(-x))\n",
    "        return val\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_regressor(w, X):\n",
    "        regressor = np.dot(w, X)\n",
    "        return LogisticRegression.sigmoid_function(regressor)\n",
    "       \n",
    "    def gradient(self, j):\n",
    "        total_error = 0\n",
    "        for i in xrange(len(self.output)):\n",
    "            xi = self.X[i]\n",
    "            xij = xi[j]\n",
    "            yi = self.output[i]\n",
    "            ri = LogisticRegression.compute_regressor(self.w, xi)\n",
    "            if yi == -1:\n",
    "                yi = 0\n",
    "            diff = xij*(yi-ri)\n",
    "            total_error += diff\n",
    "        constant = float(self.alpha)/float(len(self.output))\n",
    "        grad = constant * total_error\n",
    "        return grad\n",
    "    \n",
    "    \n",
    "    def gradient_ascent(self):\n",
    "        wi = []\n",
    "        for j in xrange(len(self.w)):\n",
    "            grad = self.gradient(j)\n",
    "            wij = self.w[j] + grad[0]\n",
    "            wi.append(wij)\n",
    "        return wi\n",
    "    \n",
    "    \n",
    "    def train(self, max_iters):\n",
    "        for counter in xrange(max_iters):\n",
    "            wi = self.gradient_ascent()\n",
    "            self.w = wi;\n",
    "    \n",
    "    def predict(self, x):\n",
    "        posterior_prob = LogisticRegression.compute_regressor(self.w, x)\n",
    "        if posterior_prob >= 0.5:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        0\n",
       "x1        0\n",
       "x2        0\n",
       "x3        0\n",
       "x4        0\n",
       "x5        0\n",
       "x6        0\n",
       "x7        0\n",
       "x8        0\n",
       "x9        0\n",
       "output    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataPath = './DataSets/breast-cancer-wisconsin.data.txt'\n",
    "columns = ['id', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'output']\n",
    "features = ['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'output']\n",
    "df = pd.read_csv(dataPath, names=columns)\n",
    "df = df.replace('?', np.nan)\n",
    "df[['x6']] = df[['x6']].apply(pd.to_numeric)\n",
    "df = df.replace(np.nan, df['x6'].mean())\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df['output'] = df['output'].apply(lambda x : 1 if x == 2 else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468\n",
      "468\n"
     ]
    }
   ],
   "source": [
    "df_X_train, df_X_test, df_y_train, df_y_test = train_test_split(df[features], df['output'], \n",
    "                                                                test_size=0.33, random_state=42)\n",
    "print len(df_X_train)\n",
    "print len(df_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n",
      "77\n",
      "77\n",
      "53\n",
      "10\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "fractions = [0.01, 0.02, 0.03, 0.125, 0.625, 1]\n",
    "training_data_size = []\n",
    "for fraction in fractions:\n",
    "    df_train = df_X_train.sample(frac=fraction)\n",
    "    training_data_size.append(len(df_train))\n",
    "    nbclassifier = NaiveBayesClassifier(df=df_train, output_col_name='output', features=features)\n",
    "    nbclassifier.train()\n",
    "    df_X_test['prediction'] = df_X_test.apply(lambda row : nbclassifier.predict(row), axis=1)\n",
    "    accuracy_results = pd.crosstab(df_X_test['prediction'], df_y_test)\n",
    "    \n",
    "    misclassifcation = 0;\n",
    "    \n",
    "    if 1 in accuracy_results:\n",
    "        if -1 in accuracy_results[1]:\n",
    "            misclassifcation += accuracy_results[1][-1]\n",
    "        \n",
    "    \n",
    "    if -1 in accuracy_results:\n",
    "        if 1 in accuracy_results[-1]:\n",
    "            misclassifcation += accuracy_results[-1][1]\n",
    "    \n",
    "    print misclassifcation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output       -1    1\n",
      "lprediction         \n",
      "-1           47   11\n",
      " 1           30  143\n",
      "output       -1    1\n",
      "lprediction         \n",
      "1            77  154\n",
      "output       -1    1\n",
      "lprediction         \n",
      "-1           35   19\n",
      " 1           42  135\n",
      "output       -1    1\n",
      "lprediction         \n",
      "-1           64   30\n",
      " 1           13  124\n",
      "output       -1    1\n",
      "lprediction         \n",
      "-1           62   23\n",
      " 1           15  131\n",
      "output       -1    1\n",
      "lprediction         \n",
      "-1           60   24\n",
      " 1           17  130\n"
     ]
    }
   ],
   "source": [
    "fractions = [0.01, 0.02, 0.03, 0.125, 0.625, 1]\n",
    "training_data_size = []\n",
    "cols = ['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9']\n",
    "#df_X_train['x0'] = df_X_train.apply(lambda row : 1)\n",
    "#df_X_test['x0'] = df_X_test.apply(lambda row : 1)\n",
    "\n",
    "for fraction in fractions:\n",
    "    df_train = df_X_train.sample(frac=fraction)\n",
    "    training_data_size.append(len(df_train))\n",
    "    w = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    \n",
    "    lr = LogisticRegression(df_train.as_matrix(columns=cols), df_train.as_matrix(columns=['output']), w, 0.1)\n",
    "    lr.train(100)\n",
    "    #print lr.w\n",
    "    df_X_test['lprediction'] = df_X_test.apply(lambda row : lr.predict(row.as_matrix(columns=cols)), axis=1)\n",
    "    accuracy_results = pd.crosstab(df_X_test['lprediction'], df_y_test)\n",
    "    print accuracy_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output       -1    1\n",
      "lprediction         \n",
      "-1           24    4\n",
      " 1           53  150\n",
      "output       -1    1\n",
      "lprediction         \n",
      "-1           38   11\n",
      " 1           39  143\n",
      "output       -1    1\n",
      "lprediction         \n",
      "-1           37    2\n",
      " 1           40  152\n",
      "output       -1    1\n",
      "lprediction         \n",
      "-1           61    7\n",
      " 1           16  147\n",
      "output       -1    1\n",
      "lprediction         \n",
      "-1           69    3\n",
      " 1            8  151\n",
      "output       -1    1\n",
      "lprediction         \n",
      "-1           71    2\n",
      " 1            6  152\n"
     ]
    }
   ],
   "source": [
    "fractions = [0.01, 0.02, 0.03, 0.125, 0.625, 1]\n",
    "training_data_size = []\n",
    "cols = ['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9']\n",
    "#df_X_train['x0'] = df_X_train.apply(lambda row : 1)\n",
    "#df_X_test['x0'] = df_X_test.apply(lambda row : 1)\n",
    "\n",
    "for fraction in fractions:\n",
    "    df_train = df_X_train.sample(frac=fraction)\n",
    "    training_data_size.append(len(df_train))\n",
    "    w = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "    w = w.reshape(1, 9)\n",
    "    lr = linear_model.LogisticRegression()\n",
    "    lr.fit(df_train[cols], df_train['output'])\n",
    "    #print lr.coef_\n",
    "    df_X_test['lprediction'] = lr.predict(df_X_test[cols])\n",
    "\n",
    "    accuracy_results = pd.crosstab(df_X_test['lprediction'], df_y_test)\n",
    "    print accuracy_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
